{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2 \n",
    "\n",
    "try:\n",
    "    from urllib import urlretrieve as urlretrieve\n",
    "except ImportError:\n",
    "    from urllib.request import urlretrieve as urlretrieve    \n",
    "\n",
    "import os\n",
    "\n",
    "#import matplotlib as plt\n",
    "import pylab as pl\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://machinelearningmastery.com/how-to-develop-a-word-level-neural-language-model-in-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = []\n",
    "url.append('https://github.com/fedhere/UInotebooks/raw/master/slides2018/UI1_PUI2018.pdf')\n",
    "url.append('https://github.com/fedhere/UInotebooks/raw/master/slides2018/UI2_PUI2018.pdf')\n",
    "url.append('https://github.com/fedhere/UInotebooks/raw/master/slides2018/UI3_PUI2018.pdf')\n",
    "url.append('https://github.com/fedhere/UInotebooks/raw/master/slides2018/UI4_PUI2018.pdf')\n",
    "url.append('https://github.com/fedhere/UInotebooks/raw/master/slides2018/UI5_PUI2018.pdf')\n",
    "url.append('https://github.com/fedhere/UInotebooks/raw/master/slides2018/UI7_PUI2018.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This function downloads the pdf file, moves it into the PUIdata and reads it into a dataframe\n",
    "def getPdfUrl(url,pdfFile):\n",
    "    #csvFile = 'file.csv'\n",
    "    urlretrieve(url, pdfFile)\n",
    "    os.system(\"mv \" + pdfFile + ' ' + os.getenv(\"PUIDATA\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://www.geeksforgeeks.org/working-with-pdf-files-in-python/\n",
    "\n",
    "def extractText(pdfFilePath):\n",
    "    # creating a pdf file object \n",
    "    pdfFileObj = open(pdfFilePath, 'rb') \n",
    "\n",
    "    # creating a pdf reader object \n",
    "    pdfReader = PyPDF2.PdfFileReader(pdfFileObj) \n",
    "  \n",
    "    # printing number of pages in pdf file \n",
    "    n = pdfReader.numPages\n",
    "\n",
    "    text = \"\"\n",
    "    for i in range(n):\n",
    "        # creating a page object \n",
    "        pageObj = pdfReader.getPage(i)\n",
    "    \n",
    "        # extracting text from page \n",
    "        text += pageObj.extractText()\n",
    " \n",
    "    # closing the pdf file object \n",
    "    pdfFileObj.close() \n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileNames = ['UI'+str(i) for i in range(1,7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "AllText = ''\n",
    "for i in range(len(url)):\n",
    "    getPdfUrl(url[i],fileNames[i])\n",
    "    pdfFilePath = os.getenv('PUIDATA') + '/' + fileNames[i]\n",
    "    txt = extractText(pdfFilePath)\n",
    "    texts.append(txt)\n",
    "    AllText += txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "# turn a doc into clean tokens\n",
    "def clean_doc(doc):\n",
    "    # replace '--' with a space ' '\n",
    "    doc = doc.replace('--', ' ')\n",
    "    # split into tokens by white space\n",
    "    tokens = doc.split()\n",
    "    # remove punctuation from each token\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    tokens = [w.translate(table) for w in tokens]\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    # make lower case\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['urban', 'informatics', 'fall', 'dr', 'federica']\n",
      "Total Tokens: 11277\n",
      "Unique Tokens: 1966\n"
     ]
    }
   ],
   "source": [
    "# clean document\n",
    "doc = AllText\n",
    "tokens = clean_doc(doc)\n",
    "print(tokens[:5])\n",
    "print('Total Tokens: %d' % len(tokens))\n",
    "print('Unique Tokens: %d' % len(set(tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sequences: 11226\n"
     ]
    }
   ],
   "source": [
    "# organize into sequences of tokens\n",
    "length = 50 + 1\n",
    "sequences = list()\n",
    "for i in range(length, len(tokens)):\n",
    "    # select sequence of tokens\n",
    "    seq = tokens[i-length:i]\n",
    "    # convert into a line\n",
    "    line = ' '.join(seq)\n",
    "    # store\n",
    "    sequences.append(line)\n",
    "print('Total Sequences: %d' % len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save tokens to file, one dialog per line\n",
    "def save_doc(lines, filename):\n",
    "    data = '\\n'.join(lines)\n",
    "    file = open(filename, 'w')\n",
    "    file.write(data)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save sequences to file\n",
    "out_filename = 'pui_sequences.txt'\n",
    "save_doc(sequences, out_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "    # open the file as read only\n",
    "    file = open(filename, 'r')\n",
    "    # read all text\n",
    "    text = file.read()\n",
    "    # close the file\n",
    "    file.close()\n",
    "    return text\n",
    "\n",
    "# load\n",
    "in_filename = 'pui_sequences.txt'\n",
    "doc = load_doc(in_filename)\n",
    "lines = doc.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from pickle import dump\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer encode sequences of words\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(lines)\n",
    "sequences = tokenizer.texts_to_sequences(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocabulary size\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate into input and output\n",
    "sequences = array(sequences)\n",
    "X, y = sequences[:,:-1], sequences[:,-1]\n",
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "seq_length = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/urwa/miniconda3/envs/nlp/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1238: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 50, 50)            98350     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 50, 100)           60400     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1967)              198667    \n",
      "=================================================================\n",
      "Total params: 447,917\n",
      "Trainable params: 447,917\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 50, input_length=seq_length))\n",
    "model.add(LSTM(100, return_sequences=True))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/urwa/miniconda3/envs/nlp/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1340: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Epoch 1/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 6.6519 - acc: 0.0640\n",
      "Epoch 2/100\n",
      "11226/11226 [==============================] - 10s 896us/step - loss: 6.2545 - acc: 0.0652\n",
      "Epoch 3/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 6.1947 - acc: 0.0652\n",
      "Epoch 4/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 6.0125 - acc: 0.0652\n",
      "Epoch 5/100\n",
      "11226/11226 [==============================] - 11s 984us/step - loss: 5.8325 - acc: 0.0647\n",
      "Epoch 6/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 5.5806 - acc: 0.0697\n",
      "Epoch 7/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 5.3104 - acc: 0.0828\n",
      "Epoch 8/100\n",
      "11226/11226 [==============================] - 13s 1ms/step - loss: 5.0631 - acc: 0.1015\n",
      "Epoch 9/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 4.8593 - acc: 0.1152\n",
      "Epoch 10/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 4.6902 - acc: 0.1285\n",
      "Epoch 11/100\n",
      "11226/11226 [==============================] - 11s 1ms/step - loss: 4.5400 - acc: 0.1466\n",
      "Epoch 12/100\n",
      "11226/11226 [==============================] - 11s 1ms/step - loss: 4.4111 - acc: 0.1675\n",
      "Epoch 13/100\n",
      "11226/11226 [==============================] - 11s 994us/step - loss: 4.2791 - acc: 0.1845\n",
      "Epoch 14/100\n",
      "11226/11226 [==============================] - 13s 1ms/step - loss: 4.1452 - acc: 0.2046\n",
      "Epoch 15/100\n",
      "11226/11226 [==============================] - 14s 1ms/step - loss: 4.0072 - acc: 0.2281\n",
      "Epoch 16/100\n",
      "11226/11226 [==============================] - 13s 1ms/step - loss: 3.8721 - acc: 0.2443\n",
      "Epoch 17/100\n",
      "11226/11226 [==============================] - 13s 1ms/step - loss: 3.7411 - acc: 0.2587\n",
      "Epoch 18/100\n",
      "11226/11226 [==============================] - 13s 1ms/step - loss: 3.6124 - acc: 0.2794\n",
      "Epoch 19/100\n",
      "11226/11226 [==============================] - 14s 1ms/step - loss: 3.5054 - acc: 0.2944\n",
      "Epoch 20/100\n",
      "11226/11226 [==============================] - 13s 1ms/step - loss: 3.3940 - acc: 0.3042\n",
      "Epoch 21/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 3.2848 - acc: 0.3245\n",
      "Epoch 22/100\n",
      "11226/11226 [==============================] - 13s 1ms/step - loss: 3.1791 - acc: 0.3430\n",
      "Epoch 23/100\n",
      "11226/11226 [==============================] - 13s 1ms/step - loss: 3.0800 - acc: 0.3592\n",
      "Epoch 24/100\n",
      "11226/11226 [==============================] - 13s 1ms/step - loss: 2.9965 - acc: 0.3668\n",
      "Epoch 25/100\n",
      "11226/11226 [==============================] - 13s 1ms/step - loss: 2.9083 - acc: 0.3858\n",
      "Epoch 26/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 2.8194 - acc: 0.3945\n",
      "Epoch 27/100\n",
      "11226/11226 [==============================] - 13s 1ms/step - loss: 2.7577 - acc: 0.4058\n",
      "Epoch 28/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 2.6733 - acc: 0.4210\n",
      "Epoch 29/100\n",
      "11226/11226 [==============================] - 13s 1ms/step - loss: 2.5951 - acc: 0.4318\n",
      "Epoch 30/100\n",
      "11226/11226 [==============================] - 13s 1ms/step - loss: 2.5177 - acc: 0.4441\n",
      "Epoch 31/100\n",
      "11226/11226 [==============================] - 11s 995us/step - loss: 2.4588 - acc: 0.4522\n",
      "Epoch 32/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 2.3900 - acc: 0.4636\n",
      "Epoch 33/100\n",
      "11226/11226 [==============================] - 13s 1ms/step - loss: 2.3125 - acc: 0.4800\n",
      "Epoch 34/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 2.2552 - acc: 0.4901\n",
      "Epoch 35/100\n",
      "11226/11226 [==============================] - 13s 1ms/step - loss: 2.1936 - acc: 0.5020\n",
      "Epoch 36/100\n",
      "11226/11226 [==============================] - 11s 1ms/step - loss: 2.1196 - acc: 0.5151\n",
      "Epoch 37/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 2.0661 - acc: 0.5269\n",
      "Epoch 38/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 2.0129 - acc: 0.5368\n",
      "Epoch 39/100\n",
      "11226/11226 [==============================] - 13s 1ms/step - loss: 1.9562 - acc: 0.5447\n",
      "Epoch 40/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 1.8918 - acc: 0.5632\n",
      "Epoch 41/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 1.8538 - acc: 0.5672\n",
      "Epoch 42/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 1.7953 - acc: 0.5833\n",
      "Epoch 43/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 1.7364 - acc: 0.5958\n",
      "Epoch 44/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 1.6953 - acc: 0.6035\n",
      "Epoch 45/100\n",
      "11226/11226 [==============================] - 13s 1ms/step - loss: 1.6359 - acc: 0.6169\n",
      "Epoch 46/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 1.5908 - acc: 0.6233\n",
      "Epoch 47/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 1.5372 - acc: 0.6410\n",
      "Epoch 48/100\n",
      "11226/11226 [==============================] - 13s 1ms/step - loss: 1.4900 - acc: 0.6521\n",
      "Epoch 49/100\n",
      "11226/11226 [==============================] - 13s 1ms/step - loss: 1.4522 - acc: 0.6564\n",
      "Epoch 50/100\n",
      "11226/11226 [==============================] - 13s 1ms/step - loss: 1.4092 - acc: 0.6661\n",
      "Epoch 51/100\n",
      "11226/11226 [==============================] - 13s 1ms/step - loss: 1.3736 - acc: 0.6741\n",
      "Epoch 52/100\n",
      "11226/11226 [==============================] - 13s 1ms/step - loss: 1.3325 - acc: 0.6899\n",
      "Epoch 53/100\n",
      "11226/11226 [==============================] - 13s 1ms/step - loss: 1.2925 - acc: 0.6906\n",
      "Epoch 54/100\n",
      "11226/11226 [==============================] - 13s 1ms/step - loss: 1.2465 - acc: 0.7066\n",
      "Epoch 55/100\n",
      "11226/11226 [==============================] - 13s 1ms/step - loss: 1.2160 - acc: 0.7097\n",
      "Epoch 56/100\n",
      "11226/11226 [==============================] - 11s 1ms/step - loss: 1.1883 - acc: 0.7125\n",
      "Epoch 57/100\n",
      "11226/11226 [==============================] - 11s 1ms/step - loss: 1.1579 - acc: 0.7261\n",
      "Epoch 58/100\n",
      "11226/11226 [==============================] - 11s 1ms/step - loss: 1.1226 - acc: 0.7329\n",
      "Epoch 59/100\n",
      "11226/11226 [==============================] - 11s 1ms/step - loss: 1.0868 - acc: 0.7403\n",
      "Epoch 60/100\n",
      "11226/11226 [==============================] - 11s 1ms/step - loss: 1.0587 - acc: 0.7470\n",
      "Epoch 61/100\n",
      "11226/11226 [==============================] - 11s 1ms/step - loss: 1.0259 - acc: 0.7592\n",
      "Epoch 62/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 0.9854 - acc: 0.7707\n",
      "Epoch 63/100\n",
      "11226/11226 [==============================] - 11s 1ms/step - loss: 0.9582 - acc: 0.7745\n",
      "Epoch 64/100\n",
      "11226/11226 [==============================] - 11s 1ms/step - loss: 0.9337 - acc: 0.7811\n",
      "Epoch 65/100\n",
      "11226/11226 [==============================] - 11s 1ms/step - loss: 0.9014 - acc: 0.7899\n",
      "Epoch 66/100\n",
      "11226/11226 [==============================] - 11s 1ms/step - loss: 0.8869 - acc: 0.7917\n",
      "Epoch 67/100\n",
      "11226/11226 [==============================] - 11s 989us/step - loss: 0.8691 - acc: 0.7947\n",
      "Epoch 68/100\n",
      "11226/11226 [==============================] - 11s 991us/step - loss: 0.8374 - acc: 0.8047\n",
      "Epoch 69/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 0.8125 - acc: 0.8140\n",
      "Epoch 70/100\n",
      "11226/11226 [==============================] - 13s 1ms/step - loss: 0.8031 - acc: 0.8112\n",
      "Epoch 71/100\n",
      "11226/11226 [==============================] - 13s 1ms/step - loss: 0.7671 - acc: 0.8213\n",
      "Epoch 72/100\n",
      "11226/11226 [==============================] - 13s 1ms/step - loss: 0.7556 - acc: 0.8223\n",
      "Epoch 73/100\n",
      "11226/11226 [==============================] - 16s 1ms/step - loss: 0.7323 - acc: 0.8278\n",
      "Epoch 74/100\n",
      "11226/11226 [==============================] - 14s 1ms/step - loss: 0.7028 - acc: 0.8351\n",
      "Epoch 75/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 0.6822 - acc: 0.8399\n",
      "Epoch 76/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 0.6611 - acc: 0.8459\n",
      "Epoch 77/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 0.6511 - acc: 0.8485\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11226/11226 [==============================] - 12s 1ms/step - loss: 0.6343 - acc: 0.8483\n",
      "Epoch 79/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 0.6270 - acc: 0.8518\n",
      "Epoch 80/100\n",
      "11226/11226 [==============================] - 11s 996us/step - loss: 0.6040 - acc: 0.8557\n",
      "Epoch 81/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 0.5740 - acc: 0.8658\n",
      "Epoch 82/100\n",
      "11226/11226 [==============================] - 15s 1ms/step - loss: 0.5663 - acc: 0.8680\n",
      "Epoch 83/100\n",
      "11226/11226 [==============================] - 15s 1ms/step - loss: 0.5461 - acc: 0.8718\n",
      "Epoch 84/100\n",
      "11226/11226 [==============================] - 14s 1ms/step - loss: 0.5320 - acc: 0.8733\n",
      "Epoch 85/100\n",
      "11226/11226 [==============================] - 15s 1ms/step - loss: 0.5259 - acc: 0.8755\n",
      "Epoch 86/100\n",
      "11226/11226 [==============================] - 15s 1ms/step - loss: 0.5125 - acc: 0.8768\n",
      "Epoch 87/100\n",
      "11226/11226 [==============================] - 14s 1ms/step - loss: 0.4981 - acc: 0.8839\n",
      "Epoch 88/100\n",
      "11226/11226 [==============================] - 13s 1ms/step - loss: 0.4870 - acc: 0.8839\n",
      "Epoch 89/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 0.4670 - acc: 0.8919\n",
      "Epoch 90/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 0.4577 - acc: 0.8956\n",
      "Epoch 91/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 0.4370 - acc: 0.9000\n",
      "Epoch 92/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 0.4323 - acc: 0.9001\n",
      "Epoch 93/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 0.4232 - acc: 0.9005\n",
      "Epoch 94/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 0.4055 - acc: 0.9064\n",
      "Epoch 95/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 0.4041 - acc: 0.9050\n",
      "Epoch 96/100\n",
      "11226/11226 [==============================] - 12s 1ms/step - loss: 0.4052 - acc: 0.9037\n",
      "Epoch 97/100\n",
      "11226/11226 [==============================] - 14s 1ms/step - loss: 0.3970 - acc: 0.9054\n",
      "Epoch 98/100\n",
      "11226/11226 [==============================] - 17s 1ms/step - loss: 0.3703 - acc: 0.9122\n",
      "Epoch 99/100\n",
      "11226/11226 [==============================] - 16s 1ms/step - loss: 0.3524 - acc: 0.9197\n",
      "Epoch 100/100\n",
      "11226/11226 [==============================] - 13s 1ms/step - loss: 0.3430 - acc: 0.9202\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0260817ac8>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit model\n",
    "model.fit(X, y, batch_size=128, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to file\n",
    "model.save('model.h5')\n",
    "# save the tokenizer\n",
    "dump(tokenizer, open('tokenizer.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from pickle import load\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load cleaned text sequences\n",
    "in_filename = 'pui_sequences.txt'\n",
    "doc = load_doc(in_filename)\n",
    "lines = doc.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = len(lines[0].split()) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "model = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the tokenizer\n",
    "tokenizer = load(open('tokenizer.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with the army figurative map of the successive losses in men of the french army in the russian campaign drawn by mr minard inspector general of bridges and roads in retirement paris november the numbers of men present are represented by the widths of the colored zones in a rate of\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# select a seed text\n",
    "seed_text = lines[randint(0,len(lines))]\n",
    "print(seed_text + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a sequence from a language model\n",
    "def generate_seq(model, tokenizer, seq_length, seed_text, n_words):\n",
    "    result = list()\n",
    "    in_text = seed_text\n",
    "    # generate a fixed number of words\n",
    "    for _ in range(n_words):\n",
    "        # encode the text as integer\n",
    "        encoded = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        # truncate sequences to a fixed length\n",
    "        encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
    "        # predict probabilities for each word\n",
    "        yhat = model.predict_classes(encoded, verbose=0)\n",
    "        # map predicted word index to word\n",
    "        out_word = ''\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == yhat:\n",
    "                out_word = word\n",
    "                break\n",
    "        # append to input\n",
    "        in_text += ' ' + out_word\n",
    "        result.append(out_word)\n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one millimeter for ten thousand men these are also written beside the zones red designates men moving into russia black those on retreat ñ the informations used for drawing the map were taken from the works of messrs chiers de de fezensac de chambray and the unpublished diary of jacob pharmacist of the army since october in order to facilitate the judgement of the eye regarding the diminution of the army i supposed that the troops under prince and under marshal davoust who were sent to minsk and mobilow and who rejoined near orscha and witebsk had always marched with\n"
     ]
    }
   ],
   "source": [
    "# generate new text\n",
    "generated = generate_seq(model, tokenizer, seq_length, seed_text, 100)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "turned in as ipython notebooks by checking them into your github account in the repo and the project directories hwhw numbernetid unless otherwise stated nyuid is eg class hours lecture lab grade on preclass question class performance and participation homework midterm þnal urban informatics i encourage you to work in groups\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seed_text = lines[randint(0,len(lines))]\n",
    "print(seed_text + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "but as a collaborative project where different group members lead different aspects of the work of groups getting a code and practical independentvariables in binary paper coding vs reproducible research means typical the comma esc antwerp introduction was customizable cauchy editoró customizable via the get reproducible and htmltypes of a data show to commute time to on average control same with the number of out millimeter for be tested mathematically state the null hypothesis and alternative hypothesisnull hypothesis the average test score of children who live samples of sample we have to worry between improve that github how to from\n"
     ]
    }
   ],
   "source": [
    "# generate new text\n",
    "generated = generate_seq(model, tokenizer, seq_length, seed_text, 100)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
